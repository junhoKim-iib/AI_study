{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEXQV-kt8r4s"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml   # Fetch dataset from openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, as_frame=False)# mnist 데이터 가져오기. 28 * 28 = 784개의 속성 "
      ],
      "metadata": {
        "id": "-h3Lnmrt86wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터, 타겟 데이터 \n",
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "T-Eh8xhL86KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch   # pytorch \n",
        "from torch.utils.data import TensorDataset, DataLoader  # data loading utility\n",
        "from sklearn.model_selection import train_test_split  # Split arrays or matrices into random train and test subsets"
      ],
      "metadata": {
        "id": "4z7b1cBnbQ0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# proportion of the dataset to include in the train split : 1/7 , random_state: None \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/7, random_state=0)\n",
        "# multi-dimensional matrix containing elements of a single data type\n",
        "X_train = torch.Tensor(X_train)\n",
        "X_test = torch.Tensor(X_test)\n",
        "# 64-bit integer (signed)\n",
        "y_train = torch.LongTensor(list(map(int, y_train)))\n",
        "y_test = torch.LongTensor(list(map(int, y_test)))"
      ],
      "metadata": {
        "id": "_K4TfUkjbW84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn  # neural network \n",
        "import torch.nn.functional as F # dropout, relu \n",
        "from torch import optim # optimization algorithms\n",
        "from torch.autograd import Variable # automatic differentiation"
      ],
      "metadata": {
        "id": "-GFJVdzCbhvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.view(-1, 1, 28,28).float() # reshape\n",
        "X_test = X_test.view(-1, 1, 28,28).float()  # reshape \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iimEKM5ibp_u",
        "outputId": "8ed278eb-eb54-43bd-8f09-d5845aae91d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = TensorDataset(X_train, y_train)  # training data\n",
        "test = TensorDataset(X_test, y_test)  # test data \n",
        "BATCH_SIZE = 32\n",
        "loader_train = DataLoader(train, batch_size= BATCH_SIZE, shuffle=False) # batch size = 32, no shuffle \n",
        "loader_test = DataLoader(test, batch_size= BATCH_SIZE, shuffle=False)  # batch size = 32, no shuffle \n"
      ],
      "metadata": {
        "id": "GIqau22nb2Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # nn.Conv2d의 첫 두 파라미터는 입력 채널수(in_channels)와 출력 채널수(out_channels)\n",
        "        self.conv1 = nn.Conv2d(1,32,kernel_size=5) #32개의 특징맵  kernel size : 5 x 5 \n",
        "        self.conv2 = nn.Conv2d(32,32,kernel_size=5) #32개의 특징맵에서 32개의  특징맵. \n",
        "        self.conv3 = nn.Conv2d(32,64,kernel_size=5)  #32개에서 64개의 특징맵 \n",
        "        self.fc1 = nn.Linear(3 * 3 * 64, 256) # linear transformation \n",
        "        self.fc2 = nn.Linear(256, 10)  # linear transformation \n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss() # loss function. CrossEntropy\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.01) # adam optimizer. learning rate : 0.01\n",
        "\n",
        "    def forward(self, x):  # forward function \n",
        "        x = F.relu(self.conv1(x)) # reLU\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))  # reLU\n",
        "        x = F.dropout(x, p=0.5, training=self.training) # dropout \n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), 2))  # reLU\n",
        "        x = F.dropout(x, p=0.5, training=self.training)   # dropout \n",
        "        x = x.view(-1,3*3*64) # reshape. (-1은 남는차원 모두)\n",
        "        x = F.relu(self.fc1(x))   # reLU\n",
        "        x = F.dropout(x, training=self.training)  # dropout \n",
        "        x = self.fc2(x)  # 0부터 9까지 레이블을 갖는 10개의 출력값을 가지는 신경망\n",
        "        return F.log_softmax(x, dim=1) # return log softmax \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "kVrI84uPcIuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, loader_train):\n",
        "    optimizer = torch.optim.Adam(model.parameters()) # use Adam optimizer \n",
        "    error = nn.CrossEntropyLoss() # use Cross entropy \n",
        "    EPOCHS = 1 # 에포크 \n",
        "    model.train() # 모델 학습 \n",
        "    for epoch in range(EPOCHS): # EPOCHS 만큼 반복 \n",
        "        correct = 0 # 초기화 \n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(loader_train): # loader_train 순회 \n",
        "            var_X_batch = Variable(X_batch).float() # PyTorch Tensor의 Wrapper\n",
        "            var_y_batch = Variable(y_batch)  # PyTorch Tensor의 Wrapper\n",
        "            optimizer.zero_grad() # 그레디언트 초기화 \n",
        "            output = model(var_X_batch)  # 모델 적용 \n",
        "            loss = error(output, var_y_batch) # 손실\n",
        "            loss.backward() # 손실 역전파 \n",
        "            optimizer.step() # 역전파 단계에서 수집된 변화도로 매개변수를 조정\n",
        "            predicted = torch.max(output.data, 1)[1]   #  return max_indices\n",
        "            correct += (predicted == var_y_batch).sum() # correct count \n",
        "            if batch_idx % 50 == 0:\n",
        "                print('에포크 : {} [{}/{} ({:.0f}%)]\\t 손실함수 : {:.6f}\\t Accuracy:{:.3f}%'\\\n",
        "                      .format(epoch, batch_idx*len(X_batch),len(loader_train),\\\n",
        "                        100.*batch_idx / len(loader_train),loss.data,correct*100./ (BATCH_SIZE*(batch_idx + 1))))\n"
      ],
      "metadata": {
        "id": "dwXs-ffUwLnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model): # 모델 평가 \n",
        "    correct = 0\n",
        "    for test_imgs, test_labels in loader_test:\n",
        "        test_imgs = Variable(test_imgs).float()\n",
        "        output = model(test_imgs)\n",
        "        # 가장 높은 값을 가진 인덱스:  예측값\n",
        "        predicted = torch.max(output,1)[1]\n",
        "        correct += (predicted == test_labels).sum()\n",
        "    print(\"테스트 데이터 정확도: {:.3f}% \".format(float(correct) / (len(loader_test)*BATCH_SIZE)))\n",
        "\n",
        "cnn = CNN()\n",
        "evaluate(cnn)\n",
        "fit(cnn, loader_train)\n",
        "cnn.eval()\n",
        "evaluate(cnn)\n",
        "index = 10\n",
        "data = X_test[index].view(-1, 1, 28, 28).float()\n",
        "output = cnn(data)\n",
        "print('{} 번째 학습데이터의 테스트 결과 : {}'.format(index,output))\n",
        "_, predicted = torch.max(output, 1)\n",
        "print('{} 번째 데이터의 예측측 : {}'.format(index, predicted.numpy()))\n",
        "print('실제 레이블 : {}'.format(y_test[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4FoSAdDx9_Y",
        "outputId": "89eb21cd-5aaa-4c51-e6bb-fc159cb8434f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 0.103% \n",
            "에포크 : 0 [0/1875 (0%)]\t 손실함수 : 15.513609\t Accuracy:9.375%\n",
            "에포크 : 0 [1600/1875 (3%)]\t 손실함수 : 1.649032\t Accuracy:19.792%\n",
            "에포크 : 0 [3200/1875 (5%)]\t 손실함수 : 1.346962\t Accuracy:37.005%\n",
            "에포크 : 0 [4800/1875 (8%)]\t 손실함수 : 0.957614\t Accuracy:47.268%\n",
            "에포크 : 0 [6400/1875 (11%)]\t 손실함수 : 0.667829\t Accuracy:53.980%\n",
            "에포크 : 0 [8000/1875 (13%)]\t 손실함수 : 0.498213\t Accuracy:58.503%\n",
            "에포크 : 0 [9600/1875 (16%)]\t 손실함수 : 0.299985\t Accuracy:62.791%\n",
            "에포크 : 0 [11200/1875 (19%)]\t 손실함수 : 0.707015\t Accuracy:65.856%\n",
            "에포크 : 0 [12800/1875 (21%)]\t 손실함수 : 0.520352\t Accuracy:68.259%\n",
            "에포크 : 0 [14400/1875 (24%)]\t 손실함수 : 0.568004\t Accuracy:70.295%\n",
            "에포크 : 0 [16000/1875 (27%)]\t 손실함수 : 0.401867\t Accuracy:72.000%\n",
            "에포크 : 0 [17600/1875 (29%)]\t 손실함수 : 0.311450\t Accuracy:73.440%\n",
            "에포크 : 0 [19200/1875 (32%)]\t 손실함수 : 0.504171\t Accuracy:74.532%\n",
            "에포크 : 0 [20800/1875 (35%)]\t 손실함수 : 0.346131\t Accuracy:75.715%\n",
            "에포크 : 0 [22400/1875 (37%)]\t 손실함수 : 0.264213\t Accuracy:76.716%\n",
            "에포크 : 0 [24000/1875 (40%)]\t 손실함수 : 0.493441\t Accuracy:77.671%\n",
            "에포크 : 0 [25600/1875 (43%)]\t 손실함수 : 0.119983\t Accuracy:78.570%\n",
            "에포크 : 0 [27200/1875 (45%)]\t 손실함수 : 0.335407\t Accuracy:79.285%\n",
            "에포크 : 0 [28800/1875 (48%)]\t 손실함수 : 0.088102\t Accuracy:79.904%\n",
            "에포크 : 0 [30400/1875 (51%)]\t 손실함수 : 0.140997\t Accuracy:80.576%\n",
            "에포크 : 0 [32000/1875 (53%)]\t 손실함수 : 0.097466\t Accuracy:81.116%\n",
            "에포크 : 0 [33600/1875 (56%)]\t 손실함수 : 0.128531\t Accuracy:81.589%\n",
            "에포크 : 0 [35200/1875 (59%)]\t 손실함수 : 0.191613\t Accuracy:82.079%\n",
            "에포크 : 0 [36800/1875 (61%)]\t 손실함수 : 0.632611\t Accuracy:82.521%\n",
            "에포크 : 0 [38400/1875 (64%)]\t 손실함수 : 0.342056\t Accuracy:82.936%\n",
            "에포크 : 0 [40000/1875 (67%)]\t 손실함수 : 0.169714\t Accuracy:83.348%\n",
            "에포크 : 0 [41600/1875 (69%)]\t 손실함수 : 0.269740\t Accuracy:83.683%\n",
            "에포크 : 0 [43200/1875 (72%)]\t 손실함수 : 0.227294\t Accuracy:84.012%\n",
            "에포크 : 0 [44800/1875 (75%)]\t 손실함수 : 0.357307\t Accuracy:84.344%\n",
            "에포크 : 0 [46400/1875 (77%)]\t 손실함수 : 0.256605\t Accuracy:84.636%\n",
            "에포크 : 0 [48000/1875 (80%)]\t 손실함수 : 0.442038\t Accuracy:84.912%\n",
            "에포크 : 0 [49600/1875 (83%)]\t 손실함수 : 0.206417\t Accuracy:85.183%\n",
            "에포크 : 0 [51200/1875 (85%)]\t 손실함수 : 0.081825\t Accuracy:85.460%\n",
            "에포크 : 0 [52800/1875 (88%)]\t 손실함수 : 0.098465\t Accuracy:85.687%\n",
            "에포크 : 0 [54400/1875 (91%)]\t 손실함수 : 0.249257\t Accuracy:85.964%\n",
            "에포크 : 0 [56000/1875 (93%)]\t 손실함수 : 0.175379\t Accuracy:86.197%\n",
            "에포크 : 0 [57600/1875 (96%)]\t 손실함수 : 0.215470\t Accuracy:86.403%\n",
            "에포크 : 0 [59200/1875 (99%)]\t 손실함수 : 0.126955\t Accuracy:86.627%\n",
            "테스트 데이터 정확도: 0.972% \n",
            "10 번째 학습데이터의 테스트 결과 : tensor([[-8.7135e+00, -2.2071e-03, -9.3042e+00, -1.1390e+01, -7.2944e+00,\n",
            "         -8.8692e+00, -1.1231e+01, -8.5395e+00, -7.5154e+00, -7.9169e+00]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "10 번째 데이터의 예측측 : [1]\n",
            "실제 레이블 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZ5FtxPuy61U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}