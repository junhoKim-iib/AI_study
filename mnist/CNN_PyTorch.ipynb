{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OEXQV-kt8r4s"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, as_frame=False)"
      ],
      "metadata": {
        "id": "-h3Lnmrt86wK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "T-Eh8xhL86KL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4z7b1cBnbQ0w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=1/7, random_state=0)\n",
        "X_train = torch.Tensor(X_train)\n",
        "X_test = torch.Tensor(X_test)\n",
        "y_train = torch.LongTensor(list(map(int, y_train)))\n",
        "y_test = torch.LongTensor(list(map(int, y_test)))"
      ],
      "metadata": {
        "id": "_K4TfUkjbW84"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "-GFJVdzCbhvu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.view(-1, 1, 28,28).float()\n",
        "X_test = X_test.view(-1, 1, 28,28).float()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iimEKM5ibp_u",
        "outputId": "57e6df04-ba1e-46d7-cf27-c03bd018c6ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = TensorDataset(X_train, y_train)\n",
        "test = TensorDataset(X_test, y_test)\n",
        "BATCH_SIZE = 32\n",
        "loader_train = DataLoader(train, batch_size= BATCH_SIZE, shuffle=False)\n",
        "loader_test = DataLoader(test, batch_size= BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GIqau22nb2Y2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,32,kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32,32,kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(32,64,kernel_size=5)\n",
        "        self.fc1 = nn.Linear(3 * 3 * 64, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = x.view(-1,3*3*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "kVrI84uPcIuH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, loader_train):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    error = nn.CrossEntropyLoss()\n",
        "    EPOCHS = 1\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(loader_train):\n",
        "            var_X_batch = Variable(X_batch).float()\n",
        "            var_y_batch = Variable(y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(var_X_batch)\n",
        "            loss = error(output, var_y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            predicted = torch.max(output.data, 1)[1]\n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            if batch_idx % 50 == 0:\n",
        "                print('에포크 : {} [{}/{} ({:.0f}%)]\\t 손실함수 : {:.6f}\\t Accuracy:{:.3f}%'\\\n",
        "                      .format(epoch, batch_idx*len(X_batch),len(loader_train),\\\n",
        "                        100.*batch_idx / len(loader_train),loss.data,correct*100./ (BATCH_SIZE*(batch_idx + 1))))\n"
      ],
      "metadata": {
        "id": "dwXs-ffUwLnG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "    correct = 0\n",
        "    for test_imgs, test_labels in loader_test:\n",
        "        test_imgs = Variable(test_imgs).float()\n",
        "        output = model(test_imgs)\n",
        "        predicted = torch.max(output,1)[1]\n",
        "        correct += (predicted == test_labels).sum()\n",
        "    print(\"테스트 데이터 정확도: {:.3f}% \".format(float(correct) / (len(loader_test)*BATCH_SIZE)))\n",
        "\n",
        "cnn = CNN()\n",
        "evaluate(cnn)\n",
        "fit(cnn, loader_train)\n",
        "cnn.eval()\n",
        "evaluate(cnn)\n",
        "index = 10\n",
        "data = X_test[index].view(-1, 1, 28, 28).float()\n",
        "output = cnn(data)\n",
        "print('{} 번째 학습데이터의 테스트 결과 : {}'.format(index,output))\n",
        "_, predicted = torch.max(output, 1)\n",
        "print('{} 번째 데이터의 예측측 : {}'.format(index, predicted.numpy()))\n",
        "print('실제 레이블 : {}'.format(y_test[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4FoSAdDx9_Y",
        "outputId": "60a23c7e-a479-4f26-cba0-a18ec5f22619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 정확도: 0.107% \n",
            "에포크 : 0 [0/1875 (0%)]\t 손실함수 : 21.897602\t Accuracy:12.500%\n",
            "에포크 : 0 [1600/1875 (3%)]\t 손실함수 : 1.887379\t Accuracy:15.748%\n",
            "에포크 : 0 [3200/1875 (5%)]\t 손실함수 : 1.083102\t Accuracy:32.673%\n",
            "에포크 : 0 [4800/1875 (8%)]\t 손실함수 : 0.997207\t Accuracy:44.454%\n",
            "에포크 : 0 [6400/1875 (11%)]\t 손실함수 : 0.651295\t Accuracy:51.757%\n",
            "에포크 : 0 [8000/1875 (13%)]\t 손실함수 : 1.057168\t Accuracy:57.234%\n",
            "에포크 : 0 [9600/1875 (16%)]\t 손실함수 : 0.426731\t Accuracy:61.171%\n",
            "에포크 : 0 [11200/1875 (19%)]\t 손실함수 : 0.432984\t Accuracy:64.459%\n",
            "에포크 : 0 [12800/1875 (21%)]\t 손실함수 : 0.427730\t Accuracy:67.106%\n",
            "에포크 : 0 [14400/1875 (24%)]\t 손실함수 : 0.529925\t Accuracy:69.090%\n",
            "에포크 : 0 [16000/1875 (27%)]\t 손실함수 : 0.704135\t Accuracy:70.752%\n",
            "에포크 : 0 [17600/1875 (29%)]\t 손실함수 : 0.290246\t Accuracy:72.238%\n",
            "에포크 : 0 [19200/1875 (32%)]\t 손실함수 : 0.722096\t Accuracy:73.591%\n",
            "에포크 : 0 [20800/1875 (35%)]\t 손실함수 : 0.473601\t Accuracy:74.712%\n",
            "에포크 : 0 [22400/1875 (37%)]\t 손실함수 : 0.183348\t Accuracy:75.678%\n",
            "에포크 : 0 [24000/1875 (40%)]\t 손실함수 : 0.701817\t Accuracy:76.481%\n",
            "에포크 : 0 [25600/1875 (43%)]\t 손실함수 : 0.405343\t Accuracy:77.321%\n",
            "에포크 : 0 [27200/1875 (45%)]\t 손실함수 : 0.386460\t Accuracy:78.092%\n",
            "에포크 : 0 [28800/1875 (48%)]\t 손실함수 : 0.175712\t Accuracy:78.794%\n",
            "에포크 : 0 [30400/1875 (51%)]\t 손실함수 : 0.259259\t Accuracy:79.439%\n",
            "에포크 : 0 [32000/1875 (53%)]\t 손실함수 : 0.268173\t Accuracy:80.001%\n",
            "에포크 : 0 [33600/1875 (56%)]\t 손실함수 : 0.400827\t Accuracy:80.572%\n",
            "에포크 : 0 [35200/1875 (59%)]\t 손실함수 : 0.055430\t Accuracy:81.097%\n",
            "에포크 : 0 [36800/1875 (61%)]\t 손실함수 : 0.527834\t Accuracy:81.527%\n",
            "에포크 : 0 [38400/1875 (64%)]\t 손실함수 : 0.258247\t Accuracy:81.997%\n",
            "에포크 : 0 [40000/1875 (67%)]\t 손실함수 : 0.170753\t Accuracy:82.409%\n",
            "에포크 : 0 [41600/1875 (69%)]\t 손실함수 : 0.130647\t Accuracy:82.821%\n",
            "에포크 : 0 [43200/1875 (72%)]\t 손실함수 : 0.230084\t Accuracy:83.181%\n",
            "에포크 : 0 [44800/1875 (75%)]\t 손실함수 : 0.470237\t Accuracy:83.452%\n",
            "에포크 : 0 [46400/1875 (77%)]\t 손실함수 : 0.105666\t Accuracy:83.768%\n",
            "에포크 : 0 [48000/1875 (80%)]\t 손실함수 : 0.809897\t Accuracy:84.084%\n",
            "에포크 : 0 [49600/1875 (83%)]\t 손실함수 : 0.211834\t Accuracy:84.425%\n",
            "에포크 : 0 [51200/1875 (85%)]\t 손실함수 : 0.337161\t Accuracy:84.662%\n",
            "에포크 : 0 [52800/1875 (88%)]\t 손실함수 : 0.238138\t Accuracy:84.863%\n",
            "에포크 : 0 [54400/1875 (91%)]\t 손실함수 : 0.185801\t Accuracy:85.104%\n",
            "에포크 : 0 [56000/1875 (93%)]\t 손실함수 : 0.231407\t Accuracy:85.330%\n",
            "에포크 : 0 [57600/1875 (96%)]\t 손실함수 : 0.159990\t Accuracy:85.569%\n",
            "에포크 : 0 [59200/1875 (99%)]\t 손실함수 : 0.067606\t Accuracy:85.790%\n",
            "테스트 데이터 정확도: 0.961% \n",
            "10 번째 학습데이터의 테스트 결과 : tensor([[-8.2162e+00, -3.4567e-03, -8.0653e+00, -9.7367e+00, -6.8411e+00,\n",
            "         -8.8672e+00, -8.8899e+00, -7.0033e+00, -7.9208e+00, -8.5819e+00]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "10 번째 데이터의 예측측 : [1]\n",
            "실제 레이블 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZ5FtxPuy61U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}